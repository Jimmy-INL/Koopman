{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sabin/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "\"\"\" EDMD with dictionary learning \"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import autograd.numpy as np\n",
    "import time\n",
    "import scipy.optimize\n",
    "from autograd import grad \n",
    "import csv\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QP functions\n",
    "def fp(x, *args):\n",
    "    \"\"\"x is column stacked (K1, K2, P)\"\"\"\n",
    "    d, A1, B1, A2, B2 = args\n",
    "    x = x.reshape(d, 3*d)\n",
    "    K1, K2, P = x[:,:d], x[:,d:2*d], x[:,2*d:3*d]\n",
    "    loss1 = np.sum((A1 - B1 @ K1)**2)\n",
    "    loss2 = np.sum((A2 - B2 @ K2)**2)\n",
    "    \n",
    "    # Enforce conjugacy between K1 and K2\n",
    "    weight = 100.0\n",
    "    conj_losses = weight*(np.sum((P @ K1 - K2 @ P)**2))\n",
    "    return loss1 + loss2 + conj_losses\n",
    "\n",
    "def jacob(fp, *args):\n",
    "    return grad(fp)\n",
    "def cons(x, *args):\n",
    "    \n",
    "    \"\"\"Regularization via constraints\"\"\"\n",
    "    eps = 0.1\n",
    "    d, A1, B1, A2, B2 = args\n",
    "    x = x.reshape(d, 3*d)\n",
    "    K1, K2, P = x[:,:d], x[:,d:2*d], x[:,2*d:3*d]\n",
    "    return np.array([np.sum(P**2)-0.5, 5.0-np.sum(P**2), np.linalg.det(P)-0.1, 0.1-np.linalg.det(P)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDMD_DL:\n",
    "    def __init__(self):\n",
    "        self.__build_flag = -1\n",
    "        self.__train_flag = -1\n",
    "\n",
    "    def build(self, dim, ddim, hdim, num_layers=3, \n",
    "              activation=tf.nn.tanh, init_lr=1e-5,\n",
    "              random_state=115):\n",
    "        \"\"\" Build tensorflow model \"\"\"\n",
    "\n",
    "        # Parameters\n",
    "        self.__random_state = random_state\n",
    "        self.__dim = dim\n",
    "        self.__ddim = ddim\n",
    "        self.__hdim = hdim\n",
    "        self.__num_layers = num_layers\n",
    "\n",
    "        kmatdim = ddim + 1 + dim\n",
    "        num_layers = self.__num_layers\n",
    "        std = 1.0 / np.sqrt(hdim)\n",
    "        std_proj = 1.0\n",
    "\n",
    "        # Form B matrix\n",
    "        self.__B = np.zeros((dim+1+ddim, dim))\n",
    "        for i in range(dim):\n",
    "            self.__B[i+1][i] = 1\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        #ops.reset_default_graph() #\n",
    "        self.__tf_nlr = activation\n",
    "        # Constants\n",
    "        # TF_PI = tf.constant(value=np.pi, dtype=tf.float64)\n",
    "        #tf.random.set_seed(42)\n",
    "        tf.set_random_seed(self.__random_state)\n",
    "        # Build graph\n",
    "\n",
    "        # Input data placeholders\n",
    "        self.__x1 = tf.placeholder(tf.float64, [None, dim])\n",
    "        self.__y1 = tf.placeholder(tf.float64, [None, dim])\n",
    "        self.__x2 = tf.placeholder(tf.float64, [None, dim])\n",
    "        self.__y2 = tf.placeholder(tf.float64, [None, dim])\n",
    "\n",
    "        # K matrices\n",
    "        with tf.variable_scope(\"K1_matrix\"):\n",
    "            self.__K1 = tf.get_variable(shape=(kmatdim, kmatdim), dtype=tf.float64,\n",
    "                                       name='K1', trainable=False)\n",
    "        with tf.variable_scope(\"K2_matrix\"):\n",
    "            self.__K2 = tf.get_variable(shape=(kmatdim, kmatdim), dtype=tf.float64,\n",
    "                                       name='K2', trainable=False)\n",
    "        \n",
    "        # Neural network approximation of dictionary elements\n",
    "        with tf.variable_scope(\"Model\", reuse=None, \n",
    "                               initializer=tf.random_uniform_initializer(maxval=std,\n",
    "                                                                         minval=-std)):\n",
    "            self.__psiNNx1 = self.__psiNN(self.__x1)\n",
    "        with tf.variable_scope(\"Model\", reuse=True):\n",
    "            self.__psiNNy1 = self.__psiNN(self.__y1)\n",
    "        with tf.variable_scope(\"Model\", reuse=True, \n",
    "                               initializer=tf.random_uniform_initializer(maxval=std,\n",
    "                                                                         minval=-std)):\n",
    "            self.__psiNNx2 = self.__psiNN(self.__x2)\n",
    "        with tf.variable_scope(\"Model\", reuse=True):\n",
    "            self.__psiNNy2 = self.__psiNN(self.__y2)\n",
    "            \n",
    "        # Loss function definition\n",
    "        self.__loss_fn = tf.reduce_mean(\n",
    "                        tf.square( (self.__psiNNy1 )\n",
    "                      - tf.matmul(self.__psiNNx1, self.__K1))\n",
    "                      + tf.square( (self.__psiNNy2 \n",
    "                      - tf.matmul(self.__psiNNx2, self.__K2)) ) )\n",
    "\n",
    "        # Optimizer\n",
    "        self.__lr_val = tf.placeholder(dtype=tf.float64, shape=())\n",
    "        self.__lr = tf.Variable(initial_value=init_lr, trainable=False,\n",
    "                                dtype=tf.float64)\n",
    "        self.__assign_lr = tf.assign(self.__lr, self.__lr_val)\n",
    "        opt_D = tf.train.AdamOptimizer(learning_rate=self.__lr)\n",
    "        self.__train_D = opt_D.minimize(self.__loss_fn)\n",
    "\n",
    "        # ridge regression to find K\n",
    "        self.__reg = tf.constant(shape=(),value=0.1,dtype=tf.float64)\n",
    "        idmat = tf.constant(shape=(kmatdim,kmatdim),value=np.identity(kmatdim),dtype=tf.float64)\n",
    "        # with tf.variable_scope(\"Model\", reuse=True):\n",
    "        #     ycurr = self.__psiNN(y)\n",
    "        #     xcurr = self.__psiNN(x)\n",
    "        xtx_inv = tf.matrix_inverse(self.__reg*idmat + \n",
    "                                    tf.matmul(tf.transpose(self.__psiNNx1),\n",
    "                                              self.__psiNNx1))\n",
    "        xty = tf.matmul(tf.transpose(self.__psiNNx1), self.__psiNNy1)\n",
    "        self.__K1_reg = tf.matmul(xtx_inv, xty)\n",
    "        self.__assignK1 = tf.assign(self.__K1, self.__K1_reg)\n",
    "        \n",
    "        # ... and K2\n",
    "        xtx_inv2 = tf.matrix_inverse(self.__reg*idmat + \n",
    "                                    tf.matmul(tf.transpose(self.__psiNNx2),\n",
    "                                              self.__psiNNx2))\n",
    "        xty2 = tf.matmul(tf.transpose(self.__psiNNx2), self.__psiNNy2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.__K2_reg = tf.matmul(xtx_inv2, xty2)\n",
    "        self.__assignK2 = tf.assign(self.__K2, self.__K2_reg)\n",
    "\n",
    "        # Update K1, K2 via placeholder\n",
    "        self.__K1ph = tf.placeholder(tf.float64, self.__K1.get_shape(), 'K1_placeholder')\n",
    "        self.__updateK1 = tf.assign(self.__K1, self.__K1ph)\n",
    "        self.__K2ph = tf.placeholder(tf.float64, self.__K2.get_shape(), 'K2_placeholder')\n",
    "        self.__updateK2 = tf.assign(self.__K2, self.__K2ph)        \n",
    "        \n",
    "        # Set Pmat\n",
    "        self.__Pmat = np.random.uniform(size=(kmatdim,kmatdim))\n",
    "\n",
    "        # Initialize session\n",
    "        self.__sess = tf.Session()\n",
    "        self.__sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Set number of parameters\n",
    "        self.__num_t_params = np.sum([np.prod(v.get_shape().as_list()) \n",
    "                                     for v in tf.trainable_variables()])\n",
    "\n",
    "        # Build complete\n",
    "        print(\"Built tensorflow graph.\")\n",
    "        self.__build_flag = 0\n",
    "    \n",
    "    def reinitialize(self):\n",
    "        assert self.__build_flag == 0, \"Run build() first.\"\n",
    "        self.__sess.run(tf.global_variables_initializer())\n",
    "        print(\"Reinitialized all variables.\")\n",
    "\n",
    "\n",
    "    def dictionary(self, data, system_id=1):\n",
    "        \"\"\" output dictionary \"\"\"\n",
    "        assert self.__build_flag == 0, \"Run build() first.\"\n",
    "        \n",
    "        if len(data.shape) == 1: # handle single sample inputs\n",
    "            data2d = data.reshape(1, data.size)\n",
    "            if system_id == 1:\n",
    "                return self.__sess.run(self.__psiNNx1,\n",
    "                                       feed_dict={self.__x1: data2d}).squeeze()\n",
    "            else:\n",
    "                return self.__sess.run(self.__psiNNx2,\n",
    "                                       feed_dict={self.__x2: data2d}).squeeze()\n",
    "        else:\n",
    "            if system_id == 1:\n",
    "                return self.__sess.run(self.__psiNNx1,\n",
    "                                       feed_dict={self.__x1: data})\n",
    "            else:\n",
    "                return self.__sess.run(self.__psiNNx2,\n",
    "                                       feed_dict={self.__x2: data})\n",
    "\n",
    "    def __set_K(self, x_data, y_data, system_id=1):\n",
    "        \"\"\" Update K matrix from training \"\"\"\n",
    "        if system_id == 1:\n",
    "            feed = {self.__x1: x_data, self.__y1: y_data, self.__reg: 0.01}\n",
    "            return self.__sess.run(self.__K1_reg, feed_dict=feed)\n",
    "        else:\n",
    "            feed = {self.__x2: x_data, self.__y2: y_data, self.__reg: 0.01}\n",
    "            return self.__sess.run(self.__K2_reg, feed_dict=feed)\n",
    "\n",
    "    def __eig_decomp(self, Kval):\n",
    "        \"\"\" Eigen-decomp of a matrix Kval \"\"\"\n",
    "        assert self.__train_flag == 0, \"Run train() first.\"\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(Kval) \n",
    "        idx = eigenvalues.real.argsort()[::-1]   \n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        eigenvectors_inv = np.linalg.inv(eigenvectors)\n",
    "        return eigenvalues, eigenvectors, eigenvectors_inv\n",
    "\n",
    "    def train(self, num_epochs, x_data1, y_data1, x_data2, y_data2, batch_size,\n",
    "              train_dict=True, verbose=True, log_interval=100, opt_interval = 10, opt_iterations = 500,\n",
    "              lr_decay=0.8):\n",
    "        \"\"\" Train step \"\"\"\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Started training.\")\n",
    "        losses = []\n",
    "        assert self.__build_flag == 0, \"Run build() first.\"        \n",
    "        start_time = time.time()\n",
    "        num_data = x_data1.shape[0]\n",
    "        no_of_batches = num_data//batch_size\n",
    "        for i in range(num_epochs):\n",
    "            # Step 1: Train K_1, K_2\n",
    "\n",
    "            # Step 1a: Get K1,K2 and set initial P\n",
    "            K1mat, K2mat = self.__sess.run([self.__K1, self.__K2])\n",
    "            # Pmat = np.random.uniform(size=K1mat.shape)\n",
    "            if i > 0 and i % opt_interval == 0:\n",
    "                \n",
    "                init_mat = np.column_stack((K1mat,K2mat,self.__Pmat))\n",
    "\n",
    "                # Step 1b: Solve constrained optimization (after network has settled a while)\n",
    "                                \n",
    "                A1mat, B1mat = self.__sess.run(\n",
    "                    [self.__psiNNy1, self.__psiNNx1],\n",
    "                    feed_dict={self.__x1: x_data1, self.__y1: y_data1})\n",
    "                A2mat, B2mat = self.__sess.run( \n",
    "                    [self.__psiNNy2, self.__psiNNx2],\n",
    "                    feed_dict={self.__x2: x_data2, self.__y2: y_data2})\n",
    "                \n",
    "                dim = K1mat.shape[0]\n",
    "                constr = ({'type': 'ineq', 'fun': cons, 'args': (dim, A1mat, B1mat, A2mat, B2mat)})\n",
    "                result = scipy.optimize.minimize(fp, init_mat, args=(dim, A1mat, B1mat, A2mat, B2mat),\n",
    "                                                 jac=dfp, constraints=constr,\n",
    "                                                 method='SLSQP', options={'disp': verbose, 'maxiter': opt_iterations})\n",
    "                \n",
    "                # Step 1d: Extract result and update K1, K2\n",
    "                result_mat = (result.x).reshape(dim, 3*dim)\n",
    "                K1mat, K2mat, self.__Pmat = (result_mat[:,:dim], result_mat[:,dim:2*dim],\n",
    "                                             result_mat[:,2*dim:3*dim])\n",
    "                \n",
    "                self.__sess.run([self.__updateK1, self.__updateK2],\n",
    "                                feed_dict={self.__K1ph: K1mat, self.__K2ph: K2mat})\n",
    "                                \n",
    "           \n",
    "            # Step 2: Train dictionary\n",
    "            if train_dict:\n",
    "                ptr = 0\n",
    "                for j in range(no_of_batches):\n",
    "                    x_batch1, y_batch1 = x_data1[ptr:ptr+batch_size], \\\n",
    "                                         y_data1[ptr:ptr+batch_size]\n",
    "                    x_batch2, y_batch2 = x_data2[ptr:ptr+batch_size], \\\n",
    "                                         y_data2[ptr:ptr+batch_size]\n",
    "                    feed = {self.__x1: x_batch1, self.__y1: y_batch1,\n",
    "                            self.__x2: x_batch2, self.__y2: y_batch2}\n",
    "                    ptr+=batch_size\n",
    "                    self.__sess.run(self.__train_D, feed_dict=feed)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            # Logging\n",
    "            if i%log_interval == 0:\n",
    "                feed = {self.__x1: x_data1, self.__y1: y_data1,\n",
    "                        self.__x2: x_data2, self.__y2: y_data2}\n",
    "                losses.append([i,self.__sess.run(self.__loss_fn,\n",
    "                               feed_dict=feed)])\n",
    "                if verbose:\n",
    "                    curr_time = time.time()\n",
    "                    print(\"Epoch - \",str(i), \\\n",
    "                    \" Loss - \", losses[-1][1], \\\n",
    "                    \" LR - \", self.__sess.run(self.__lr), \\\n",
    "                    \"Time - \", curr_time - start_time)\n",
    "                    start_time = curr_time\n",
    "                    \n",
    "                # Adjust learning rate:\n",
    "                if len(losses)>2:\n",
    "                    if losses[-1][1] > losses[-2][1]:\n",
    "                        print(\"Error increased. Decay learning rate\")\n",
    "                        curr_lr = self.__sess.run(self.__lr)\n",
    "                        self.__sess.run(self.__assign_lr,\n",
    "                                        feed_dict={self.__lr_val: lr_decay*curr_lr})\n",
    "        \n",
    "        # Update train flag\n",
    "        self.__train_flag = 0\n",
    "        \n",
    "        # Set final K\n",
    "        self.__Kval1 = self.__set_K(x_data1, y_data1, system_id=1)\n",
    "        self.__Kval2 = self.__set_K(x_data2, y_data2, system_id=2)\n",
    "        \n",
    "        # Perform Eigendecomp of K 1 and 2\n",
    "        self.__eigenvalues1, self.__eigenvectors1, self.__eigenvectors1_inv = self.__eig_decomp(self.__Kval1)\n",
    "        self.__eigenvalues2, self.__eigenvectors2, self.__eigenvectors2_inv = self.__eig_decomp(self.__Kval2)\n",
    "\n",
    "        # Calculate modes\n",
    "        self.__modes1 = np.matmul(self.__eigenvectors1_inv, self.__B).T\n",
    "        self.__modes2 = np.matmul(self.__eigenvectors2_inv, self.__B).T\n",
    "\n",
    "        print (\"Completed \", num_epochs, \"epochs.\")\n",
    "        return losses\n",
    "\n",
    "\n",
    "    def __dictNN(self, x):\n",
    "        # Parameters\n",
    "        dim = self.__dim\n",
    "        hdim = self.__hdim\n",
    "        ddim = self.__ddim\n",
    "        kmatdim = ddim + 1 + dim\n",
    "        num_layers = self.__num_layers\n",
    "        std = 1.0 / np.sqrt(hdim)\n",
    "        std_proj = 1.0 / np.sqrt(dim)\n",
    "        with tf.variable_scope(\"Input_projection\", \n",
    "                               initializer=tf.random_uniform_initializer(\n",
    "                                maxval=std_proj, minval=-std_proj)):\n",
    "            P = tf.get_variable(name='weights',\n",
    "                                shape=(dim,hdim),\n",
    "                                dtype=tf.float64)\n",
    "            res_in = tf.matmul(x, P)\n",
    "        with tf.variable_scope(\"Residual\"):\n",
    "            for j in range(self.__num_layers):\n",
    "                layer_name = \"Layer_\"+str(j)\n",
    "                with tf.variable_scope(layer_name):\n",
    "                    W = tf.get_variable(name=\"weights\", shape=(hdim,hdim),\n",
    "                                        dtype=tf.float64)\n",
    "                    b = tf.get_variable(name=\"biases\", shape=(hdim),\n",
    "                                        dtype=tf.float64)\n",
    "                    if j==0: # first layer\n",
    "                        res_out = res_in + self.__tf_nlr(\n",
    "                            tf.matmul(res_in, W) + b)\n",
    "                    else: # subsequent layers\n",
    "                        res_out = res_out + self.__tf_nlr(\n",
    "                            tf.matmul(res_out, W) + b)\n",
    "        with tf.variable_scope(\"Output_projection\",\n",
    "                            initializer=tf.random_uniform_initializer(\n",
    "                            maxval=std, minval=-std)):\n",
    "            W = tf.get_variable(name=\"weights\", shape=(hdim, ddim),\n",
    "                            dtype=tf.float64)\n",
    "            b = tf.get_variable(name=\"biases\", shape=(ddim),\n",
    "                            dtype=tf.float64)\n",
    "            out = tf.matmul(res_out, W) + b\n",
    "    #                 out = tf.nn.sigmoid(out)\n",
    "    #                 out = tf.tan(TF_PI*(out-0.5))\n",
    "        return out\n",
    "\n",
    "    def __psiNN(self, data):\n",
    "        \"\"\"returns psi(data) where psi is approximated by a residual NN\"\"\"\n",
    "        \n",
    "        zout = []\n",
    "        # Constant map\n",
    "        zout.append(tf.ones_like(tf.slice(data,[0,0],[-1,1])))\n",
    "        \n",
    "        # Skip connection (identity map)\n",
    "        zout.append(data)\n",
    "        \n",
    "        # Residual net\n",
    "        zout = zout+[self.__dictNN(data)]\n",
    "        \n",
    "        return tf.concat(zout, axis=1)\n",
    "\n",
    "    def eigenfunctions(self, data, system_id=1):\n",
    "        \"\"\" estimated eigenfunctions \"\"\"\n",
    "        psix = self.dictionary(data,system_id)\n",
    "        if system_id == 1:\n",
    "            val = np.matmul(psix, self.__eigenvectors1)\n",
    "        else:\n",
    "            val = np.matmul(psix, self.__eigenvectors2)\n",
    "        return val\n",
    "\n",
    "    def predict(self, x0, traj_len, system_id=1):\n",
    "        \"\"\" predict the trajectory \"\"\"\n",
    "        # assert x0.shape == (1, self.__dim), \"Please input correct x0.\"\n",
    "        traj = [x0.squeeze()]\n",
    "        for i in range(traj_len-1):\n",
    "            x_curr = traj[-1].reshape(1, self.__dim)\n",
    "            efunc = self.eigenfunctions(x_curr, system_id).flatten()\n",
    "            if system_id == 1:\n",
    "                x_next = np.matmul(self.__modes1, self.__eigenvalues1*efunc)\n",
    "            else:\n",
    "                x_next = np.matmul(self.__modes2, self.__eigenvalues2*efunc)\n",
    "            traj.append(x_next.real)\n",
    "        return np.asarray(traj)\n",
    "        \n",
    "    def get_h(self, z10, z20):\n",
    "        \"\"\" return the transformation function h with h(x1)=x2,\n",
    "            given one matching pair h(z10)=z20. \"\"\"\n",
    "        assert self.__train_flag == 0, \"Run train() first.\"  \n",
    "        psi10 = self.dictionary(z10, system_id = 1)\n",
    "        psi20 = self.dictionary(z20, system_id = 2)\n",
    "        print('e-vals 1: ', self.__eigenvalues1)\n",
    "        print('e-vals 2: ', self.__eigenvalues2)\n",
    "        Dup = np.matmul(self.__eigenvectors2.T, psi20.reshape(psi20.shape[0],1))\n",
    "        Ddown = np.matmul(self.__eigenvectors1.T, psi10.reshape(psi10.shape[0],1))\n",
    "        D = np.diag((Dup / Ddown).flatten())\n",
    "        \n",
    "        def h(data):\n",
    "            A = self.dictionary(data, system_id=1).T\n",
    "            A = np.matmul(self.__eigenvectors1.T, A)\n",
    "            A = np.matmul(D, A)\n",
    "            A = np.matmul(np.linalg.inv(self.__eigenvectors2.T), A)\n",
    "            A = np.matmul(self.__B.T, A)\n",
    "            return np.real(A.T)\n",
    "        return h\n",
    "\n",
    "    @property\n",
    "    def num_trainable_params(self):\n",
    "        \"\"\" Output number of trainable parameters \"\"\"\n",
    "        return self.__num_t_params\n",
    "\n",
    "    # @property\n",
    "    def eigenvalues(self, system_id=1):\n",
    "        \"\"\" Output eigenvalues of K \"\"\"\n",
    "        if system_id == 1:\n",
    "            return self.__eigenvalues1\n",
    "        else:\n",
    "            return self.__eigenvalues2\n",
    "\n",
    "    # @property\n",
    "    def modes(self, system_id = 1):\n",
    "        \"\"\" output Koopman modes \"\"\"\n",
    "        if system_id == 1:\n",
    "            return self.__modes1\n",
    "        else:\n",
    "            return self.__modes2\n",
    "\n",
    "    def get_K(self, system_id=1):\n",
    "        \"\"\" output K matrix \"\"\"\n",
    "        assert self.__build_flag == 0, \"Run build() first.\"\n",
    "        if system_id == 1:\n",
    "            return self.__Kval1\n",
    "        else:\n",
    "            return self.__Kval2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filename):\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=' ')\n",
    "        line_count = 0\n",
    "        simtime = []\n",
    "        endtime = []\n",
    "        startX = []\n",
    "        startY = []\n",
    "        endX = []\n",
    "        endY = []\n",
    "        for row in csv_reader:\n",
    "            if line_count!=0:\n",
    "                if int(row[0]) == 1:\n",
    "                    simtime.append(float(row[1]))\n",
    "                    endtime.append(float(row[2]))\n",
    "                    startX.append(float(row[3]))\n",
    "                    startY.append(float(row[4]))\n",
    "                    endX.append(float(row[5]))\n",
    "                    endY.append(float(row[6]))\n",
    "            line_count=1\n",
    "    data = np.array([np.array(simtime), np.array(endtime), np.array(startX), np.array(startY), np.array(endX),  np.array(endY)])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_file(\"postvis.traj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edmdNN = EDMD_DL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built tensorflow graph.\n"
     ]
    }
   ],
   "source": [
    "edmdNN.build(3, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (6, 34) for Tensor 'Placeholder:0', which has shape '(?, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-eb3f692affba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0medmdNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-3b40b8138e4d>\u001b[0m in \u001b[0;36mdictionary\u001b[0;34m(self, data, system_id)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msystem_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 return self.__sess.run(self.__psiNNx1,\n\u001b[0;32m--> 146\u001b[0;31m                                        feed_dict={self.__x1: data})\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 return self.__sess.run(self.__psiNNx2,\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1157\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (6, 34) for Tensor 'Placeholder:0', which has shape '(?, 3)'"
     ]
    }
   ],
   "source": [
    "edmdNN.dictionary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 34)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2       ,  0.81867873,  1.43735747,  2.0560362 ,  2.67471494,\n",
       "        3.29339367,  3.91207241,  4.53075114,  5.14942987,  5.76810861,\n",
       "        6.38678734,  7.00546608,  7.62414481,  8.24282355,  8.86150228,\n",
       "        9.48018102, 10.09885975, 10.71753848, 11.33621722, 11.95489595,\n",
       "       12.57357469, 13.19225342, 13.81093216, 14.42961089, 15.04828962,\n",
       "       15.66696836, 16.28564709, 16.90432583, 17.52300456, 18.1416833 ,\n",
       "       18.76036203, 19.37904076, 19.9977195 , 20.61639823])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
